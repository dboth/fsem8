Dokumentation Projekt 7: Algorithmus zur Ontologisierung semantischer Relationen
Dominik Both, Svenja Lohse, Tonio Weidler
"Formale Semantik", Anette Frank, WS 14/15
================================================================================

Ziele
-----
Ziel unseres Projekts ist die Kreation eines Algorithmus, der Verbpaaren, die in Relation zueinander stehen, 
die richtigen Sensepaare zuteilt.
Mithilfe des Assoziationsmaßes über zwei Korpora und Lesk-Maß von Wordnet-Glossen sollen die wahrscheinlichsten Senses 
ausgewählt werden.

Vorgehen
--------
Ein manuelles Auswählen der Senses bildet die Grundlage zur Berechnung des Goldstandards; die relationalen Senses stehen im 
von Tremper & Frank erforschten "Semantic Relations Data Set" zur Verfügung.

Annahmen: 
1. Zwei Verb(-senses) die in einer Relation zueinander stehen, haben eine höhere Kookurrenz und einen höheren Lesk-Wert als
Verb(-senses) ohne Kookurrenz.
2. Die Troponyme zweier Verben stehen in der selben Relation zueinander wie ihre Verben.
3. Eine Relation induziert immer ein bestimmtes Sensepaar.
4. Die Art der Relation ist irrelevant in Bezug auf die Kookurrenz.

Wie bei Tremper & Frank und in den 20. Vorlesungsfolien soll eine korpusbasierte WSD weiterhelfen.
Die Korpora SemCor und OntoNotes dienen zunächst als Quelle, um Kookurrenz der Verbpaare und deren Senses zu zählen.
Die gewählten Korpora sind mit Lemmata annotiert. Da Senses eine homomorphe Abbildung von Lemmata auf Senses sind, also jedem Sense
mehrere Lemmata aber jedem Lemma nur ein Sense zugeordnet werden kann, untersuchen wir wenn wir wenn wir die Lemmata in Senses
übersetzen automatisch die Synonyme der Lemmata also der Verbpaare.
Es wurden zwei Algorithmen geschrieben, die aus den Korpora die Kookurrenz in ihrer Häufigkeit extrahieren und zu einem 
.json-File zusammenfügen und in der Datei all_verbs.json speichern:

Ausschnitt:
_________________________________________________________________
{"develop.v.19,lie.v.06": 2, "get_rid_of.v.01,trace.v.01": 2, "contain.v.05,lose.v.08": 3, "develop.v.19,lie.v.02": 2, 
"get_rid_of.v.01,trace.v.05": 1, "develop.v.19,lie.v.01": 2, "contain.v.05,lose.v.02": 3, "bring.v.01,erupt.v.01": 2}
_________________________________________________________________

Die Datei verb_ontologization.py, bzw. die Klasse OntologyWSD liest nun dieses File ein und enthält Methoden um Features zu berechnen.
Als Features wurde zunächst ausschließlich ein Assoziationsmaß zwischen den Senses gewählt. Beim ersten Blick wurde aber schon klar dass dies
zu keinem guten Ergebnis führen kann. Deshalb wurde Lesk als Feature hinzugefügt. Die Evaluation nach den folgenden Schritten hat
außerdem gezeigt dass unter der 2. Annahme ein schlechteres Ergebnis erzielt wird als wenn die Nullhypothese angenommen wird.
Deshalb wurde als drittes Feature die Relation gewählt.
Ein Algorithmus kalkuliert nun für alle Sensepaare die für die Verbpaare aus dem Goldstandard möglich sind die Featurevektoren und
gibt ein Label -/+ an. + umfasst alle Vektoren die laut Goldstandard korrekt sind, - alle anderen.

Die Datei weka.py ruft die Klasse auf und übersetzt die erhaltenen Informationen in eine .arff Datei die von WeKa lesbar ist.

Ausschnitt:
_________________________________________________________________
@RELATION ontolo_new_trop

@ATTRIBUTE cooc NUMERIC
@ATTRIBUTE lesk NUMERIC
@ATTRIBUTE relation {"ant","tmp","ent","pre"}
@ATTRIBUTE correct {"+","-"}


@DATA
0.03993288590604027,1,ent,-
0,0,ent,-
0.016129032258064516,0,pre,-
0,0,ant,-
0.32589285714285715,1,ent,-
0,0,ant,-
0.012307692307692308,0,pre,-
0,1,ant,-
0,0,ant,-
0,0,ant,-
0,1,tmp,-
1.0,3,tmp,+
1.0,3,tmp,+
1.0,3,tmp,+
1.0,3,tmp,+
1.0,3,tmp,+
1.0,3,tmp,+
1.0,3,tmp,+
...
_________________________________________________________________

Das Assoziationsmaß ("cooc") wurde berechnet indem die Kookurrenz der Sensepaare und derer Troponyme durch die Kookurrenz 
aller Sensepaare relativiert wurde, die einen der beiden Senses und einen anderen Sense der für das andere Verb möglich ist enthalten.
Dieses Vorgehen orientiert sich an Jurafsky & Martin. Der Einbezug der Troponyme fußt auf Annahme 2..

Lesk ("lesk") wird berechnet indem die Zahl der gemeinsamen Wörter in den WordNet-Beschreibungen berechnet wurde.

Mit diesen Ergebnissen klassifiziert nun das Data-Mining-Programm Weka unsere Sensepaare mithilfe des 
Simple Logistic Algorithm. Leider ist das erhaltene Verhältnis von + und - Label zu groß. Deshalb haben wir positiv gelabelten Vektoren 
vervielfältigt.

Das aus "Grundlagen der Statistik" und "Machine Learning" bekannte Verfahren der Klassifikation, 
das auch Tremper & Frank zur Annotation ihres oben erwähnten Data-Sets anwenden, wird von Weka automatisch vollzogen. Die Feature-Gewichtungen, 
die Weka bestimmt, sind für die finale Auswahl der Senses notwendig und werden in einen Algorithmus übernommen,
der die Senses anhand der Features "predicted".

Mit der Klasse Chooser (chooseSense.py) kalkulieren wir das (theoretisch) wahrscheinlichste Sense-Paar zweier Verben in 
ihrer Relation. Hierzu wird für ein Verbpaar der Featurevektor berechnet und mithilfe der Gewichtungen ein Wert berechnet. 
Es wird das Sensepaar gewählt, das den maximalen Wert erreicht, weil es am weitesten von der - Klasse entfernt ist, also
am wahrscheinlichsten für das Verbpaar.

Die Funktionsweisen der einzelnen Methoden und Klassen finden sich im Readme.

Evaluation
----------
Die Evaluation der Ergebnisse wurde auf die Trainingsdaten angewandt.
Es wurde ein Kongruenzwert berechnet, der angibt, wie groß der Anteil der Sensepaare ist, die vom Algorithmus genauso 
bestimmt wurden wie im Goldstandard.
Der bestimmte Kongruenzwert ist: 7.6923076923076925

Ein zweiter Wert soll angeben wie groß der Anteil einzelner richtig gewählter Senses ist:
Congruence: 0.20512820512820512
Completely correctly predicted Pairs: 3
Partially correctly predicted Pairs: 10

Beide Werte zeugen von einem schlechten Ergebnis. Offensichtlich lässt sich der Sense zweier Verben anhand ihrer Relation nicht
einfach durch die gewählten Features bestimmen, bzw. nicht durch die gewählte Methode.

Erkenntnisse
------------
Erste Komplikationen entstanden schon bei der manuellen Auswahl der Senses für den Goldstandard, 
da manche Verben in ihrer Relation ambige Bedeutungen besitzen können. D.h. selbst in einer Relation sind mehrere Sensepaare
möglich für ein Verbpaar. (Bsp: „strenghten-weaken“, 1: makes strong or stronger – lessen the strength of; 2: gain strength – become weaker). 
Wir entschieden trotzdem manuell mit unserem Weltwissen; durch diverse Wahrscheinlichkeitsberechnungen könnte eine 
Disambiguierung stattfinden. Alternativ hätte der Goldstandard auch mehrere Sensepaare pro Verbpaar enthalten können.

Korpusassoziationsmaße und Lesk alleine führen leider zu keinem sehr guten Ergebnis des Algorithmus.
Zusätzliche Maße (wordnet path distance, wordnet antonyms etc.) und das Hinzuziehen weiterer Korpora, somit einer dichteren 
Verbkookurrenz, könnten in einem nächsten Schritt umgesetzt werden.

Auch die Wahl von Clustering mit den Relationen als Klassen anstatt der Klassifikation könnte ein besseres Ergebnis liefern.
Im aktuellen Verfahren wählt Weka Gewichtungen so, dass hinsichtlich der richtigen +/- Labelung optimiert wurde. Da aber mehrere
Sensepaare das + Label erhalten können, wurde das Paar mit dem höchsten Wert gewählt. Hiernach wurde die Gewichtung jedoch nicht optimiert.
Eventuell können bessere Ergebnisse erzielt werden, wenn das Optimierungsverfahren besser gewählt wird. 
